{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Scripts and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, cv2\n",
    "\n",
    "# ProDiVis-specific imports\n",
    "import norm_heatmap\n",
    "import normalize\n",
    "import tools\n",
    "import heatmap_workflow_tools as hwt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Setting up Filesystem\n",
    "### *User input required!*\n",
    "\n",
    "Before running the code, please ensure your filesystem consists of a parent directory with the ProDiVis repository and any dataset repositories cloned within. An example filesystem could look like the following:\n",
    "\n",
    "\n",
    "`üìÅ<parent_directory>`\n",
    "```\n",
    "‚îî‚îÄ‚îÄ üìÅProDiVis\n",
    "    ‚îî‚îÄ‚îÄüìÅScripts \n",
    "        ‚îî‚îÄ‚îÄ Data_Pipeline.ipynb\n",
    "        ‚îî‚îÄ‚îÄ *.py\n",
    "    ‚îî‚îÄ‚îÄüìÅdata\n",
    "        ‚îî‚îÄ‚îÄüìÅsignal_stack\n",
    "        ‚îî‚îÄ‚îÄüìÅnormalization_stack\n",
    "```\n",
    "\n",
    "`‚îî‚îÄ‚îÄ üìÅProDiVis_Images` <span style=\"color:green\"><em># clone if desired</em></span>\n",
    "\n",
    "The repositories containing the glioblastoma and mouse heart datasets can be found at the links below:\n",
    " - [**ProDiVis_Images**](https://github.com/FrancoLaboratory/ProDiVis-Images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In quotes, type the path to the directory containing the ProDiVis repository:\n",
    "WORKING_DIRECTORY = \"/home/asathler/repos\"\n",
    "\n",
    "# What is your signal of interest (SOI) and normalization signal (NS) \n",
    "SOI = \"Name of SOI\"\n",
    "NS = \"Name of NS\"\n",
    "\n",
    "# Replace with slice integers or decimal percentages. 'None' for no boundary\n",
    "ZMIN, ZMAX = None, None\n",
    "\n",
    "# Do you want to multiply the pixels in the front and side views (int)?\n",
    "Z_MULTIPLIER = 10\n",
    "\n",
    "# Do you want to save your figures? (boolean)\n",
    "SAVE_FIGS = False\n",
    "\n",
    "# Adjust the lower and upper threshold (int). 'None' to use bit-depth of input images\n",
    "LOWER_THRESH = None\n",
    "UPPER_THRESH = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = tools.get_int_input(hwt.SELECTION_PROMPT, 1, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pre-Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if selection == 1:\n",
    "    DATA_DIRECTORY = os.path.join(WORKING_DIRECTORY, \"ProDiVis\", \"data\")\n",
    "elif selection == 2:\n",
    "    DATA_DIRECTORY = os.path.join(WORKING_DIRECTORY, \"ProDiVis_Images\", \"Cluster_Actin\")\n",
    "else:\n",
    "    raise ValueError(f\"Selection {selection} not recognized\")\n",
    "\n",
    "STACK_DIR = os.path.join(DATA_DIRECTORY, \"signal_stack\")\n",
    "NORM_DIR = os.path.join(DATA_DIRECTORY, \"normalization_stack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed ZMin and ZMax: 0, 57\n"
     ]
    }
   ],
   "source": [
    "stack_tiffs = tools.get_files(STACK_DIR, exclude_ext = ['.md'])\n",
    "norm_tiffs = tools.get_files(NORM_DIR, exclude_ext = ['.md'])\n",
    "\n",
    "ZMIN, ZMAX = hwt.process_zmin_zmax(ZMIN, ZMAX, stack_tiffs)\n",
    "print(f\"Processed ZMin and ZMax: {ZMIN}, {ZMAX}\")\n",
    "\n",
    "stack_name = SOI #os.path.basename(STACK_DIR)\n",
    "norm_name = NS #os.path.basename(NORM_DIR)\n",
    "base_dir = DATA_DIRECTORY #os.path.basename(os.path.dirname(NORM_DIR))\n",
    "\n",
    "EXPORT_DIRECTORY = os.path.abspath(os.path.join(os.path.abspath(''), '..', 'exported_data'))\n",
    "if not os.path.isdir(EXPORT_DIRECTORY):\n",
    "    os.makedirs(EXPORT_DIRECTORY, exist_ok=True)\n",
    "\n",
    "OUTPUT_DIRECTORY = os.path.join(EXPORT_DIRECTORY, f\"EXPORT_{base_dir}_{stack_name}n{norm_name}\")\n",
    "if not os.path.isdir(OUTPUT_DIRECTORY):\n",
    "    os.makedirs(OUTPUT_DIRECTORY, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking filesystem\n",
    "for directory in [WORKING_DIRECTORY, STACK_DIR, NORM_DIR, OUTPUT_DIRECTORY]:\n",
    "    try:\n",
    "        assert os.path.isdir(directory)\n",
    "    except:\n",
    "        raise AssertionError(f\"Directory of path {directory} was not found. Please validate user inputs in above cells and ensure filesystem matches that depicted above before moving forward.\")\n",
    "        sys.exit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Images Above Threshold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_imgs = normalize.analyze_images(NORM_DIR, LOWER_THRESH)\n",
    "norm_imgs = normalize.images_used(norm_imgs, norm_tiffs, stack_tiffs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signal of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOI_imgs = normalize.analyze_images(STACK_DIR, LOWER_THRESH)\n",
    "SOI_imgs = normalize.images_used(SOI_imgs, norm_tiffs, stack_tiffs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise Image Histograms and Distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOI Depth Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 10\n",
    "histograms = np.zeros((len(stack_tiffs[ZMIN:ZMAX]), nbins))\n",
    "for idx, img in enumerate(stack_tiffs[ZMIN:ZMAX]):\n",
    "    tiff = normalize.thresh(img, LOWER_THRESH, UPPER_THRESH, 1)\n",
    "    hist, bins = np.histogram(tiff, bins = nbins)\n",
    "    histograms[idx] = hist\n",
    "histograms[histograms == 0] = 1\n",
    "bin_labels = [\"{}-{}\".format(round(bins[i-1],1), round(bins[i],1)) for i in range(1, len(bins))]\n",
    "hwt.plot_histograms(histograms, f\"{base_dir} {stack_name} z{ZMIN}-{ZMAX} SOI Heatmap of Histograms\",\n",
    "os.path.join(OUTPUT_DIRECTORY, f\"{base_dir}_{stack_name}_z{ZMIN}-{ZMAX}_SOI_Histograms.pdf\"), bin_labels, SAVE_FIGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_means = np.array([])\n",
    "for img in stack_tiffs[ZMIN:ZMAX]:\n",
    "    mean = normalize.tiff_stats_thresh(img, LOWER_THRESH, UPPER_THRESH, 1)\n",
    "    stack_means = np.append(stack_means, mean)\n",
    "hwt.plot_MSI(stack_means,\n",
    "             f\"{base_dir} {stack_name} z{ZMIN}-{ZMAX}\",\n",
    "             os.path.join(OUTPUT_DIRECTORY, f\"{base_dir}_{stack_name}_z{ZMIN}-{ZMAX}_SOI_Intensity.pdf\"), SAVE_FIGS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NS Depth Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 10\n",
    "histograms = np.zeros((len(stack_tiffs[ZMIN:ZMAX]), nbins))\n",
    "for idx, img in enumerate(norm_tiffs[ZMIN:ZMAX]):\n",
    "    tiff = normalize.thresh(img, 0, 254, 1)\n",
    "    hist, bins = np.histogram(tiff, bins = nbins)\n",
    "    histograms[idx] = hist\n",
    "histograms[histograms == 0] = 1\n",
    "bin_labels = [\"{}-{}\".format(round(bins[i-1],1), round(bins[i],1)) for i in range(1, len(bins))]\n",
    "hwt.plot_histograms(histograms, f\"{base_dir} {stack_name} z{ZMIN}-{ZMAX} NS Heatmap of Histograms\",\n",
    "os.path.join(OUTPUT_DIRECTORY, f\"{base_dir}_{stack_name}_z{ZMIN}-{ZMAX}_NS_Histograms.pdf\"), bin_labels, SAVE_FIGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_means = np.array([])\n",
    "for norm_tiff in norm_tiffs[ZMIN:ZMAX]:\n",
    "    mean = normalize.tiff_stats_thresh(norm_tiff, 0, 254, 1)\n",
    "    norm_means = np.append(norm_means, mean)\n",
    "hwt.plot_MSI(norm_means,\n",
    "             f\"{base_dir} {norm_name} z{ZMIN}-{ZMAX}\",\n",
    "             os.path.join(OUTPUT_DIRECTORY, f\"{base_dir}_{stack_name}_z{ZMIN}-{ZMAX}_NS_Intensity.pdf\"), SAVE_FIGS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NS vs SOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwt.plot_MSI_SOI_ns(SOI, NS, stack_means, norm_means, f\"{base_dir} {stack_name} {norm_name} z{ZMIN}-{ZMAX}\",\n",
    "             os.path.join(OUTPUT_DIRECTORY, f\"{base_dir}_{stack_name}n{norm_name}_z{ZMIN}-{ZMAX}_SOI_vs_NS.pdf\"), SAVE_FIGS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNIP Raw Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = norm_heatmap.stack(stack_tiffs[ZMIN:ZMAX], ['z', 'x', 'y'], Z_MULTIPLIER)\n",
    "hwt.plot_MIP(imgs, f\"{base_dir} {stack_name} z{ZMIN}-{ZMAX}\", \n",
    "                os.path.join(OUTPUT_DIRECTORY, f\"{base_dir}_{stack_name}_z{ZMIN}-{ZMAX}_HeatMap.pdf\"), SAVE_FIGS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_stack_tiffs = normalize.mean_normalizer(stack_tiffs[ZMIN:ZMAX], norm_tiffs[ZMIN:ZMAX], LOWER_THRESH, UPPER_THRESH, True, False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pixel Distribution Post-Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_stack_means = np.array([])\n",
    "for norm_stack_tiff in norm_stack_tiffs[ZMIN:ZMAX]:\n",
    "    mean = normalize.tiff_stats_thresh(norm_stack_tiff, 0, 255, 1)\n",
    "    norm_stack_means = np.append(norm_stack_means, mean)\n",
    "hwt.plot_MSI(norm_stack_means,\n",
    "             f\"{base_dir} {stack_name} norm {norm_name} z{ZMIN}-{ZMAX}\",\n",
    "             os.path.join(OUTPUT_DIRECTORY, f\"{base_dir}_{stack_name}n{norm_name}_z{ZMIN}-{ZMAX}_Normalized_SOI_Intensity.pdf\"), SAVE_FIGS)\n",
    "\n",
    "hwt.plot_MSI_grouped(stack_means, norm_means, norm_stack_means, f\"{base_dir} {stack_name} norm {norm_name} z{ZMIN}-{ZMAX}_Grouped\",\n",
    "                os.path.join(OUTPUT_DIRECTORY, f\"{base_dir}_{stack_name}n{norm_name}_z{ZMIN}-{ZMAX}_Normalized_Intensity_grouped.pdf\"), SAVE_FIGS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNIP Normalized Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = norm_heatmap.stack(norm_stack_tiffs[ZMIN:ZMAX], ['z', 'x', 'y'], Z_MULTIPLIER)\n",
    "hwt.plot_MIP(imgs, f\"{base_dir} {stack_name} norm {norm_name} z{ZMIN}-{ZMAX}\", \n",
    "                os.path.join(OUTPUT_DIRECTORY, f\"{base_dir}_{stack_name}n{stack_name}_z{ZMIN}-{ZMAX}_Normalized_HeatMap.pdf\"), SAVE_FIGS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.stack_gui(norm_stack_tiffs, norm_tiffs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert Path to Scaled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_norm_stack_tiffs = os.path.abspath(\"/Users/Kyle/Desktop/prodivis_public_repo/prodivis/sample_data/scaled_green_SOI_rn_blue_ns_254std_nblue_ns\")\n",
    "scaled_norm_stack_tiffs = tools.get_files(scaled_norm_stack_tiffs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pixel Distribution of Scaled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 10\n",
    "histograms = np.zeros((len(scaled_norm_stack_tiffs[ZMIN:ZMAX]), nbins))\n",
    "for idx, img in enumerate(scaled_norm_stack_tiffs[ZMIN:ZMAX]):\n",
    "    tiff = normalize.thresh(img, 0, 255, 1)\n",
    "    hist, bins = np.histogram(tiff, bins = nbins)\n",
    "    histograms[idx] = hist\n",
    "histograms[histograms == 0] = 1\n",
    "bin_labels = [\"{}-{}\".format(round(bins[i-1],1), round(bins[i],1)) for i in range(1, len(bins))]\n",
    "hwt.plot_histograms(histograms, f\"{base_dir} {stack_name} z{ZMIN}-{ZMAX} Normalized SOI Heatmap of Histograms\",\n",
    "os.path.join(OUTPUT_DIRECTORY, f\"{base_dir}_{stack_name}_z{ZMIN}-{ZMAX}_Scaled_Normalized_SOI_Histograms.pdf\"), bin_labels, SAVE_FIGS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized Depth Loss of Scaled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_norm_stack_means = np.array([])\n",
    "for scaled_norm_stack_tiff in scaled_norm_stack_tiffs[ZMIN:ZMAX]:\n",
    "    mean = normalize.tiff_stats_thresh(scaled_norm_stack_tiff, 0, 255, 1)\n",
    "    scaled_norm_stack_means = np.append(scaled_norm_stack_means, mean)\n",
    "hwt.plot_MSI(scaled_norm_stack_means,\n",
    "             f\"Scaled_{base_dir} {stack_name} norm {norm_name} z{ZMIN}-{ZMAX}_\",\n",
    "             os.path.join(OUTPUT_DIRECTORY, f\"{base_dir}_{stack_name}n{norm_name}_z{ZMIN}-{ZMAX}_Scaled_Normalized_SOI_Intensity.pdf\"), SAVE_FIGS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNIP Normalized Heatmap of Scaled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_imgs = norm_heatmap.stack(scaled_norm_stack_tiffs[ZMIN:ZMAX], ['z', 'x', 'y'], Z_MULTIPLIER)\n",
    "hwt.plot_MIP(scaled_imgs, f\"{base_dir} {stack_name} norm {norm_name} z{ZMIN}-{ZMAX}\", \n",
    "                os.path.join(OUTPUT_DIRECTORY, f\"{base_dir}_{stack_name}n{stack_name}_z{ZMIN}-{ZMAX}_Scaled_Normalized_HeatMap.pdf\"), SAVE_FIGS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prodivis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff3431025cdf4ad032e405a8f91ed819f1eecb2244599d348fb173dddb112472"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
